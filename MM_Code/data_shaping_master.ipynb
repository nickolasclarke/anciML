{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file processes all data to have a 'date' and 'hr_beg' column (in UTC to deal with DST issues) and to have one row per hour (ie, to be ready to be combined into a ML-ready dataframe). energy prices and AS prices still could use more DST troubleshooting if there's time, since they skip from 0 to 2 instead of 1 to 3 in hr_beg for march"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "from shapely.geometry import Point, MultiPoint, Polygon, MultiPolygon\n",
    "from shapely.affinity import scale\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import datetime\n",
    "import pytz\n",
    "from pytz import timezone\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_utc(df):\n",
    "    \"\"\"Requires dataframe with column 'dt' with datetime\"\"\"\n",
    "    central = timezone('America/Chicago')\n",
    "    df['Central'] = df['dt'].apply(lambda x: central.localize(x))\n",
    "    df['UTC'] = df['Central'].apply(lambda x: pytz.utc.normalize(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \n",
    "\n",
    "# 1. AS prices -- DONE\n",
    "Was badly encoded originally for DST; still has problems in November, but March should be resolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/margaretmccall/Documents/2020 Spring/CE 295/0 - Final Project/data_dump_will/'\n",
    "df_as = pd.read_csv(path+'AS_price_v3.csv')\n",
    "df_as['dt'] = pd.to_datetime(df_as['Local Datetime (Hour Beginning)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting timezones to UTC\n",
    "df_as = get_utc(df_as)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correcting for march errors, anyway (March should have no 2am, should be 1am)\n",
    "dst_years = np.arange(2008,2020)\n",
    "dst_start_days = [9, 8, 14, 13, 11, 10, 9, 8, 13, 12, 11, 10] #march. \n",
    "dst_end_days = [2, 1, 7, 6, 4, 3, 2, 1, 6, 5, 4, 3] #nov\n",
    "start_dates = []\n",
    "end_dates = []\n",
    "\n",
    "for i, year in enumerate(dst_years):\n",
    "    start_dates.append(pd.Timestamp(datetime.datetime(year,3,dst_start_days[i],2,0)))\n",
    "    end_dates.append(datetime.datetime(year,11,dst_end_days[i],2,0))\n",
    "\n",
    "for start in start_dates:\n",
    "    df_as['dt'][df_as['dt']==start] = df_as['dt'][df_as['dt']==start] - datetime.timedelta(hours = 1)\n",
    "df_as = get_utc(df_as)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting hr_beg and date from UTC datetime\n",
    "df_as['date'] = df_as['UTC'].dt.date\n",
    "df_as['hr_beg'] = df_as['UTC'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_as = df_as[['Market','Price Type','date','hr_beg','Price $/MWh','Volume MWh']]\n",
    "df_as.columns = ['market','product','date','hr_beg','price','volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_as.drop_duplicates(keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = ['Down Regulation', 'Non-Spinning Reserve', 'Responsive Reserve','Up Regulation']\n",
    "new_products = ['REGDN','NSPIN','RRS','REGUP']\n",
    "market = 'DAH'\n",
    "\n",
    "as_output = df_as.loc[:,'date':'hr_beg']\n",
    "\n",
    "for i, prod in enumerate(products):\n",
    "    subset = df_as.loc[(df_as['market']==market) & (df_as['product']==prod),['date','hr_beg','price','volume']].rename(columns={'price':'price'+\"_\"+market+\"_\"+new_products[i],\n",
    "                                                                                                                'volume':'vol'+\"_\"+market+\"_\"+new_products[i]})\n",
    "    as_output = as_output.merge(subset, how=\"outer\", on=['date','hr_beg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "as_output.drop_duplicates(inplace=True)\n",
    "as_output.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "as_output.to_csv(\"df_AS_price_vol.csv\", index=False) #hr_beg now in utc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \n",
    "\n",
    "\n",
    "\n",
    "# 2. AS Plan -- DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading all data and concatenating\n",
    "path = r'/Users/margaretmccall/Documents/2020 Spring/CE 295/0 - Final Project/Data--ERCOT/DAM AS Plan'\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "df_plan = pd.concat((pd.read_csv(f) for f in all_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plan.drop_duplicates(subset=['DeliveryDate','HourEnding','AncillaryType','Quantity'], \n",
    "                        keep=\"first\", inplace=True)\n",
    "df_plan.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining date and time to single datetime (and converting to hr_beg to deal with 24:00)\n",
    "df_plan['hr_end'] = df_plan['HourEnding'].apply(lambda x: int(x[:2]))\n",
    "df_plan['HourBeginning'] = df_plan['hr_end'] - 1\n",
    "df_plan.drop(columns=['hr_end'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plan['HourBeginning_str'] = df_plan['HourBeginning'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plan['HourBeginning_str'][df_plan['HourBeginning']>=10] = df_plan['HourBeginning'][df_plan['HourBeginning']>=10].astype(str) + \":00\"\n",
    "df_plan['HourBeginning_str'][df_plan['HourBeginning']<10] = \"0\" + df_plan['HourBeginning'][df_plan['HourBeginning']<10].astype(str) + \":00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plan['dt'] = pd.to_datetime(df_plan['DeliveryDate'] + \" \" + df_plan['HourBeginning_str'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plan = get_utc(df_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting hr_beg and date from UTC datetime\n",
    "df_plan['date'] = df_plan['UTC'].dt.date\n",
    "df_plan['hr_beg'] = df_plan['UTC'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plan.drop(columns=['HourEnding','DSTFlag','DeliveryDate','HourBeginning',\n",
    "                     'HourBeginning_str','dt','Central','UTC'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = df_plan['AncillaryType'].unique()\n",
    "output = df_plan.loc[df_plan['AncillaryType']==products[0],['date','hr_beg','Quantity']]\n",
    "output.rename(columns={'Quantity':products[0]+\"_\"+'Quantity'}, inplace=True)\n",
    "\n",
    "for prod in products[1:]:\n",
    "    x = df_plan.loc[df_plan['AncillaryType']==prod, ['date','hr_beg','Quantity']]\n",
    "    output = output.merge(x, how='outer', on=['date','hr_beg'])\n",
    "    output.rename(columns={'Quantity':prod+\"_\"+'Quantity'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv(\"df_as_plan.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   \n",
    "\n",
    "\n",
    "# 3. AS Bids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "#loading all data and concatenating\n",
    "path = r'/Users/margaretmccall/Documents/2020 Spring/CE 295/0 - Final Project/Data--ERCOT/Aggregated Ancillary Service Offer Curve'\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "df_bids = pd.concat((pd.read_csv(f) for f in all_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['OFFNS', 'ONNS', 'REGDN', 'REGUP', 'RRSGN', 'RRSNC', 'RRSLD'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bids['AncillaryType'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bids.drop_duplicates(subset=['AncillaryType','DeliveryDate','HourEnding','Price','Quantity'],\n",
    "                   keep='first', inplace=True)\n",
    "df_bids.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining date and time to single datetime (and converting to hr_beg to deal with 24:00)\n",
    "df_bids['hr_end'] = df_bids['HourEnding'].apply(lambda x: int(x[:2]))\n",
    "df_bids['HourBeginning'] = df_bids['hr_end'] - 1\n",
    "df_bids.drop(columns=['hr_end'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'df_bids_all.pickle'\n",
    "with open(filename, 'wb') as fp:\n",
    "    pickle.dump(df_bids, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bids['HourBeginning_str'] = df_bids['HourBeginning'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bids['HourBeginning_str'][df_bids['HourBeginning']>=10] = df_bids['HourBeginning'][df_bids['HourBeginning']>=10].astype(str) + \":00\"\n",
    "df_bids['HourBeginning_str'][df_bids['HourBeginning']<10] = \"0\" + df_bids['HourBeginning'][df_bids['HourBeginning']<10].astype(str) + \":00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bids['dt'] = pd.to_datetime(df_bids['DeliveryDate'] + \" \" + df_bids['HourBeginning_str'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_dates = df_bids['dt'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_dates = pd.DataFrame({'dt':unique_dates})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_dates = get_utc(unique_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_utc = unique_dates[['dt','UTC']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_utc.index=unique_utc['dt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_utc.drop(columns=['dt'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_utc = unique_utc.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bids['UTC'] = df_bids['dt'].map(unique_utc['UTC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2014-01-12 06:00:00+0000', tz='UTC')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bids['UTC'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting hr_beg and date from UTC datetime\n",
    "df_bids['date'] = df_bids['UTC'].dt.date\n",
    "df_bids['hr_beg'] = df_bids['UTC'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AncillaryType</th>\n",
       "      <th>DSTFlag</th>\n",
       "      <th>DeliveryDate</th>\n",
       "      <th>HourEnding</th>\n",
       "      <th>Price</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>HourBeginning</th>\n",
       "      <th>HourBeginning_str</th>\n",
       "      <th>dt</th>\n",
       "      <th>UTC</th>\n",
       "      <th>date</th>\n",
       "      <th>hr_beg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OFFNS</td>\n",
       "      <td>N</td>\n",
       "      <td>01/12/2014</td>\n",
       "      <td>01:00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>214.0</td>\n",
       "      <td>0</td>\n",
       "      <td>00:00</td>\n",
       "      <td>2014-01-12</td>\n",
       "      <td>2014-01-12 06:00:00+00:00</td>\n",
       "      <td>2014-01-12</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OFFNS</td>\n",
       "      <td>N</td>\n",
       "      <td>01/12/2014</td>\n",
       "      <td>01:00</td>\n",
       "      <td>50.01</td>\n",
       "      <td>2039.0</td>\n",
       "      <td>0</td>\n",
       "      <td>00:00</td>\n",
       "      <td>2014-01-12</td>\n",
       "      <td>2014-01-12 06:00:00+00:00</td>\n",
       "      <td>2014-01-12</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OFFNS</td>\n",
       "      <td>N</td>\n",
       "      <td>01/12/2014</td>\n",
       "      <td>01:00</td>\n",
       "      <td>60.01</td>\n",
       "      <td>2104.0</td>\n",
       "      <td>0</td>\n",
       "      <td>00:00</td>\n",
       "      <td>2014-01-12</td>\n",
       "      <td>2014-01-12 06:00:00+00:00</td>\n",
       "      <td>2014-01-12</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OFFNS</td>\n",
       "      <td>N</td>\n",
       "      <td>01/12/2014</td>\n",
       "      <td>01:00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1891.0</td>\n",
       "      <td>0</td>\n",
       "      <td>00:00</td>\n",
       "      <td>2014-01-12</td>\n",
       "      <td>2014-01-12 06:00:00+00:00</td>\n",
       "      <td>2014-01-12</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OFFNS</td>\n",
       "      <td>N</td>\n",
       "      <td>01/12/2014</td>\n",
       "      <td>01:00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1869.0</td>\n",
       "      <td>0</td>\n",
       "      <td>00:00</td>\n",
       "      <td>2014-01-12</td>\n",
       "      <td>2014-01-12 06:00:00+00:00</td>\n",
       "      <td>2014-01-12</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  AncillaryType DSTFlag DeliveryDate HourEnding  Price  Quantity  \\\n",
       "0         OFFNS       N   01/12/2014      01:00   0.01     214.0   \n",
       "1         OFFNS       N   01/12/2014      01:00  50.01    2039.0   \n",
       "2         OFFNS       N   01/12/2014      01:00  60.01    2104.0   \n",
       "3         OFFNS       N   01/12/2014      01:00  10.00    1891.0   \n",
       "4         OFFNS       N   01/12/2014      01:00   5.00    1869.0   \n",
       "\n",
       "   HourBeginning HourBeginning_str         dt                       UTC  \\\n",
       "0              0             00:00 2014-01-12 2014-01-12 06:00:00+00:00   \n",
       "1              0             00:00 2014-01-12 2014-01-12 06:00:00+00:00   \n",
       "2              0             00:00 2014-01-12 2014-01-12 06:00:00+00:00   \n",
       "3              0             00:00 2014-01-12 2014-01-12 06:00:00+00:00   \n",
       "4              0             00:00 2014-01-12 2014-01-12 06:00:00+00:00   \n",
       "\n",
       "         date  hr_beg  \n",
       "0  2014-01-12       6  \n",
       "1  2014-01-12       6  \n",
       "2  2014-01-12       6  \n",
       "3  2014-01-12       6  \n",
       "4  2014-01-12       6  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bids.drop(columns=['HourEnding','HourBeginning','HourBeginning_str','DSTFlag','dt','UTC','DeliveryDate'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'df_bids_justincase.pickle'\n",
    "with open(filename, 'wb') as fp:\n",
    "    pickle.dump(df_bids, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping bid data\n",
    "Original version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df_bids.groupby(['AncillaryType','dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregation = {\n",
    "    'Unweighted Average Price': pd.NamedAgg(column='Price', aggfunc='mean'),\n",
    "    'Max Price': pd.NamedAgg(column='Price', aggfunc='max'),\n",
    "    'Min Price': pd.NamedAgg(column='Price', aggfunc='min'),\n",
    "    'Total Quantity': pd.NamedAgg(column='Quantity', aggfunc='sum'),\n",
    "    'Number of Bids': pd.NamedAgg(column='Price', aggfunc='size')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#want weighted average price\n",
    "def wavg(group, avg_name, weight_name):\n",
    "    \"\"\" https://pbpython.com/weighted-average.html\n",
    "    \"\"\"\n",
    "    d = group[avg_name]\n",
    "    w = group[weight_name]\n",
    "    try:\n",
    "        return (d * w).sum() / w.sum()\n",
    "    except ZeroDivisionError:\n",
    "        return d.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.Series(grouped.apply(wavg, \"Price\", \"Quantity\"), name=\"Weighted Avg Price\")\n",
    "grouped_data = pd.concat([grouped.agg(**aggregation), x], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = df_bids['AncillaryType'].unique()\n",
    "output = grouped_data.loc[(products[0]),:]\n",
    "output.columns = [products[0] + \"_\" + str(col) for col in output.columns]\n",
    "\n",
    "for prod in products[1:]:\n",
    "    x = grouped_data.loc[(prod),:]\n",
    "    x.columns = [prod + \"_\" + str(col) for col in x.columns]\n",
    "    output = pd.concat([output, x], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = get_utc(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting hr_beg and date from UTC datetime\n",
    "output['date'] = output['UTC'].dt.date\n",
    "output['hr_beg'] = output['UTC'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>OFFNS_Unweighted Average Price</th>\n",
       "      <th>OFFNS_Max Price</th>\n",
       "      <th>OFFNS_Min Price</th>\n",
       "      <th>OFFNS_Total Quantity</th>\n",
       "      <th>OFFNS_Number of Bids</th>\n",
       "      <th>OFFNS_Weighted Avg Price</th>\n",
       "      <th>ONNS_Unweighted Average Price</th>\n",
       "      <th>ONNS_Max Price</th>\n",
       "      <th>ONNS_Min Price</th>\n",
       "      <th>ONNS_Total Quantity</th>\n",
       "      <th>ONNS_Number of Bids</th>\n",
       "      <th>ONNS_Weighted Avg Price</th>\n",
       "      <th>REGDN_Unweighted Average Price</th>\n",
       "      <th>REGDN_Max Price</th>\n",
       "      <th>REGDN_Min Price</th>\n",
       "      <th>REGDN_Total Quantity</th>\n",
       "      <th>REGDN_Number of Bids</th>\n",
       "      <th>REGDN_Weighted Avg Price</th>\n",
       "      <th>REGUP_Unweighted Average Price</th>\n",
       "      <th>REGUP_Max Price</th>\n",
       "      <th>REGUP_Min Price</th>\n",
       "      <th>REGUP_Total Quantity</th>\n",
       "      <th>REGUP_Number of Bids</th>\n",
       "      <th>REGUP_Weighted Avg Price</th>\n",
       "      <th>RRSGN_Unweighted Average Price</th>\n",
       "      <th>RRSGN_Max Price</th>\n",
       "      <th>RRSGN_Min Price</th>\n",
       "      <th>RRSGN_Total Quantity</th>\n",
       "      <th>RRSGN_Number of Bids</th>\n",
       "      <th>RRSGN_Weighted Avg Price</th>\n",
       "      <th>RRSNC_Unweighted Average Price</th>\n",
       "      <th>RRSNC_Max Price</th>\n",
       "      <th>RRSNC_Min Price</th>\n",
       "      <th>RRSNC_Total Quantity</th>\n",
       "      <th>RRSNC_Number of Bids</th>\n",
       "      <th>RRSNC_Weighted Avg Price</th>\n",
       "      <th>RRSLD_Unweighted Average Price</th>\n",
       "      <th>RRSLD_Max Price</th>\n",
       "      <th>RRSLD_Min Price</th>\n",
       "      <th>RRSLD_Total Quantity</th>\n",
       "      <th>RRSLD_Number of Bids</th>\n",
       "      <th>RRSLD_Weighted Avg Price</th>\n",
       "      <th>Central</th>\n",
       "      <th>UTC</th>\n",
       "      <th>date</th>\n",
       "      <th>hr_beg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-10-12</td>\n",
       "      <td>7.505714</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1396.0</td>\n",
       "      <td>7</td>\n",
       "      <td>9.063517</td>\n",
       "      <td>11.58</td>\n",
       "      <td>18.51</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13277.0</td>\n",
       "      <td>7</td>\n",
       "      <td>13.514449</td>\n",
       "      <td>13.065</td>\n",
       "      <td>60.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12273.0</td>\n",
       "      <td>12</td>\n",
       "      <td>14.872349</td>\n",
       "      <td>13.023077</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>11205.0</td>\n",
       "      <td>13</td>\n",
       "      <td>16.162925</td>\n",
       "      <td>10.39</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>23621.0</td>\n",
       "      <td>13</td>\n",
       "      <td>15.215243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>335.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010-10-12 00:00:00-05:00</td>\n",
       "      <td>2010-10-12 05:00:00+00:00</td>\n",
       "      <td>2010-10-12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dt  OFFNS_Unweighted Average Price  OFFNS_Max Price  \\\n",
       "0 2010-10-12                        7.505714             20.0   \n",
       "\n",
       "   OFFNS_Min Price  OFFNS_Total Quantity  OFFNS_Number of Bids  \\\n",
       "0             0.01                1396.0                     7   \n",
       "\n",
       "   OFFNS_Weighted Avg Price  ONNS_Unweighted Average Price  ONNS_Max Price  \\\n",
       "0                  9.063517                          11.58           18.51   \n",
       "\n",
       "   ONNS_Min Price  ONNS_Total Quantity  ONNS_Number of Bids  \\\n",
       "0             2.0              13277.0                    7   \n",
       "\n",
       "   ONNS_Weighted Avg Price  REGDN_Unweighted Average Price  REGDN_Max Price  \\\n",
       "0                13.514449                          13.065             60.0   \n",
       "\n",
       "   REGDN_Min Price  REGDN_Total Quantity  REGDN_Number of Bids  \\\n",
       "0              3.0               12273.0                    12   \n",
       "\n",
       "   REGDN_Weighted Avg Price  REGUP_Unweighted Average Price  REGUP_Max Price  \\\n",
       "0                 14.872349                       13.023077             50.0   \n",
       "\n",
       "   REGUP_Min Price  REGUP_Total Quantity  REGUP_Number of Bids  \\\n",
       "0             0.99               11205.0                    13   \n",
       "\n",
       "   REGUP_Weighted Avg Price  RRSGN_Unweighted Average Price  RRSGN_Max Price  \\\n",
       "0                 16.162925                           10.39             30.0   \n",
       "\n",
       "   RRSGN_Min Price  RRSGN_Total Quantity  RRSGN_Number of Bids  \\\n",
       "0             0.01               23621.0                    13   \n",
       "\n",
       "   RRSGN_Weighted Avg Price  RRSNC_Unweighted Average Price  RRSNC_Max Price  \\\n",
       "0                 15.215243                             0.0              0.0   \n",
       "\n",
       "   RRSNC_Min Price  RRSNC_Total Quantity  RRSNC_Number of Bids  \\\n",
       "0              0.0                 335.9                     1   \n",
       "\n",
       "   RRSNC_Weighted Avg Price  RRSLD_Unweighted Average Price  RRSLD_Max Price  \\\n",
       "0                       0.0                             NaN              NaN   \n",
       "\n",
       "   RRSLD_Min Price  RRSLD_Total Quantity  RRSLD_Number of Bids  \\\n",
       "0              NaN                   NaN                   NaN   \n",
       "\n",
       "   RRSLD_Weighted Avg Price                   Central  \\\n",
       "0                       NaN 2010-10-12 00:00:00-05:00   \n",
       "\n",
       "                        UTC        date  hr_beg  \n",
       "0 2010-10-12 05:00:00+00:00  2010-10-12       5  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.drop(columns=['dt','Central','UTC'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv(\"df_as_bid_aggregated_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping bid data -- new version\n",
    "Reg down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'df_bids_justincase.pickle'\n",
    "with open(filename, 'rb') as fp:\n",
    "    df_bids = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bids = df_bids[df_bids['AncillaryType']=='REGDN']\n",
    "df_bids.drop(columns=['AncillaryType'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bids.sort_values(by=['date','hr_beg','Price'], inplace=True)\n",
    "df_bids.reset_index(inplace=True, drop=True)\n",
    "\n",
    "df_bids['year'] = pd.to_datetime(df_bids['date']).dt.year\n",
    "df_bids = df_bids[df_bids['year']>2013]\n",
    "df_bids.reset_index(inplace=True, drop=True)\n",
    "df_bids.drop(columns=['year'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_at_percentile(group, price_name, quant_name, percentile):\n",
    "    \"\"\" https://pbpython.com/weighted-average.html\n",
    "    \"\"\"\n",
    "    p = group[price_name]\n",
    "    q = group[quant_name]\n",
    "    return p[q.where (q > max(q)*percentile).first_valid_index()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "x90 = pd.DataFrame(pd.Series(df_bids.groupby(['date','hr_beg']).apply(price_at_percentile, \"Price\", \"Quantity\",.9), name=\"90th Pctl Bid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "x80 = pd.DataFrame(pd.Series(df_bids.groupby(['date','hr_beg']).apply(price_at_percentile, \"Price\", \"Quantity\",.8), name=\"80th Pctl Bid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "x70 = pd.DataFrame(pd.Series(df_bids.groupby(['date','hr_beg']).apply(price_at_percentile, \"Price\", \"Quantity\",.7), name=\"70th Pctl Bid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "x60 = pd.DataFrame(pd.Series(df_bids.groupby(['date','hr_beg']).apply(price_at_percentile, \"Price\", \"Quantity\",.6), name=\"60th Pctl Bid\"))\n",
    "x50 = pd.DataFrame(pd.Series(df_bids.groupby(['date','hr_beg']).apply(price_at_percentile, \"Price\", \"Quantity\",.5), name=\"50th Pctl Bid\"))\n",
    "x30 = pd.DataFrame(pd.Series(df_bids.groupby(['date','hr_beg']).apply(price_at_percentile, \"Price\", \"Quantity\",.3), name=\"30th Pctl Bid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "x90.reset_index(inplace=True)\n",
    "x80.reset_index(inplace=True)\n",
    "x70.reset_index(inplace=True)\n",
    "x60.reset_index(inplace=True)\n",
    "x50.reset_index(inplace=True)\n",
    "x30.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = x90.merge(x80, how='left', on=['date','hr_beg'])\n",
    "output = output.merge(x70, how='left', on=['date','hr_beg'])\n",
    "output = output.merge(x60, how='left', on=['date','hr_beg'])\n",
    "output = output.merge(x50, how='left', on=['date','hr_beg'])\n",
    "output = output.merge(x30, how='left', on=['date','hr_beg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hr_beg</th>\n",
       "      <th>90th Pctl Bid</th>\n",
       "      <th>80th Pctl Bid</th>\n",
       "      <th>70th Pctl Bid</th>\n",
       "      <th>60th Pctl Bid</th>\n",
       "      <th>50th Pctl Bid</th>\n",
       "      <th>30th Pctl Bid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>7.13</td>\n",
       "      <td>5.65</td>\n",
       "      <td>3.93</td>\n",
       "      <td>2.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>18.55</td>\n",
       "      <td>12.63</td>\n",
       "      <td>8.11</td>\n",
       "      <td>6.48</td>\n",
       "      <td>5.55</td>\n",
       "      <td>2.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>19.04</td>\n",
       "      <td>14.11</td>\n",
       "      <td>8.11</td>\n",
       "      <td>6.36</td>\n",
       "      <td>5.19</td>\n",
       "      <td>2.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>20.24</td>\n",
       "      <td>14.11</td>\n",
       "      <td>10.00</td>\n",
       "      <td>8.11</td>\n",
       "      <td>5.55</td>\n",
       "      <td>2.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>21.68</td>\n",
       "      <td>14.11</td>\n",
       "      <td>11.00</td>\n",
       "      <td>8.11</td>\n",
       "      <td>6.91</td>\n",
       "      <td>2.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  hr_beg  90th Pctl Bid  80th Pctl Bid  70th Pctl Bid  \\\n",
       "0  2014-01-01       0          25.00          11.00           7.13   \n",
       "1  2014-01-01       1          18.55          12.63           8.11   \n",
       "2  2014-01-01       2          19.04          14.11           8.11   \n",
       "3  2014-01-01       3          20.24          14.11          10.00   \n",
       "4  2014-01-01       4          21.68          14.11          11.00   \n",
       "\n",
       "   60th Pctl Bid  50th Pctl Bid  30th Pctl Bid  \n",
       "0           5.65           3.93           2.08  \n",
       "1           6.48           5.55           2.11  \n",
       "2           6.36           5.19           2.11  \n",
       "3           8.11           5.55           2.11  \n",
       "4           8.11           6.91           2.11  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv(\"as_bids_REGDOWN.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reg up\n",
    "Reg up, which is correlated with reg down prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'df_bids_justincase.pickle'\n",
    "with open(filename, 'rb') as fp:\n",
    "    df_bids = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bids = df_bids[df_bids['AncillaryType']=='REGUP']\n",
    "df_bids.drop(columns=['AncillaryType'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bids.sort_values(by=['date','hr_beg','Price'], inplace=True)\n",
    "df_bids.reset_index(inplace=True, drop=True)\n",
    "\n",
    "df_bids['year'] = pd.to_datetime(df_bids['date']).dt.year\n",
    "df_bids = df_bids[df_bids['year']>2013]\n",
    "df_bids.reset_index(inplace=True, drop=True)\n",
    "df_bids.drop(columns=['year'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x90 = pd.DataFrame(pd.Series(df_bids.groupby(['date','hr_beg']).apply(price_at_percentile, \"Price\", \"Quantity\",.9), name=\"90th Pctl Bid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x80 = pd.DataFrame(pd.Series(df_bids.groupby(['date','hr_beg']).apply(price_at_percentile, \"Price\", \"Quantity\",.8), name=\"80th Pctl Bid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x70 = pd.DataFrame(pd.Series(df_bids.groupby(['date','hr_beg']).apply(price_at_percentile, \"Price\", \"Quantity\",.7), name=\"70th Pctl Bid\"))\n",
    "x60 = pd.DataFrame(pd.Series(df_bids.groupby(['date','hr_beg']).apply(price_at_percentile, \"Price\", \"Quantity\",.6), name=\"60th Pctl Bid\"))\n",
    "x50 = pd.DataFrame(pd.Series(df_bids.groupby(['date','hr_beg']).apply(price_at_percentile, \"Price\", \"Quantity\",.5), name=\"50th Pctl Bid\"))\n",
    "x30 = pd.DataFrame(pd.Series(df_bids.groupby(['date','hr_beg']).apply(price_at_percentile, \"Price\", \"Quantity\",.3), name=\"30th Pctl Bid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in [x90, x80, x70, x60, x50, x30]:\n",
    "    d.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in [x90, x80, x70, x60, x50, x30]:\n",
    "    d.rename(columns = {d.columns[2]:d.columns[2]+\"_REGUP\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = x90.merge(x80, how='left', on=['date','hr_beg'])\n",
    "output = output.merge(x70, how='left', on=['date','hr_beg'])\n",
    "output = output.merge(x60, how='left', on=['date','hr_beg'])\n",
    "output = output.merge(x50, how='left', on=['date','hr_beg'])\n",
    "output = output.merge(x30, how='left', on=['date','hr_beg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv(\"as_bids_REGUP.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \n",
    "\n",
    "# 4. Energy prices -- DONE\n",
    "Had DST issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/margaretmccall/Documents/2020 Spring/CE 295/0 - Final Project/data_dump_will/'\n",
    "df_energy = pd.read_csv(path+'energy_price.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting to UTC\n",
    "df_energy['dt'] = pd.to_datetime(df_energy['Local Datetime (Hour Ending)'])\n",
    "df_energy = get_utc(df_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting UTC hour ending to UTC hour beginning, and extracting date and hr_beg from there\n",
    "df_energy['UTC_hr_beg'] = df_energy['UTC'] - datetime.timedelta(hours = 1)\n",
    "df_energy['date'] = df_energy['UTC_hr_beg'].dt.date\n",
    "df_energy['hr_beg'] = df_energy['UTC_hr_beg'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subsetting to columns of interest\n",
    "df_energy = df_energy[['Price Node Name','Price Type','Market','date','hr_beg','Price $/MWh']].reset_index(drop=True)\n",
    "df_energy.columns = ['node','price_type','market','date','hr_beg','price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshaping data\n",
    "nodes = ['HB_BUSAVG', 'HB_HOUSTON', 'HB_HUBAVG', 'HB_NORTH', 'HB_SOUTH','HB_WEST']\n",
    "newnodes = ['busavg','houston','hubavg','N','S','W']\n",
    "markets = ['DAH', 'RT15AVG']\n",
    "newmarkets = ['DAH','RT15']\n",
    "\n",
    "energy_output = df_energy.loc[:,'date':'hr_beg']\n",
    "\n",
    "for i, market in enumerate(markets):\n",
    "    for j, node in enumerate(nodes):\n",
    "        subset = df_energy.loc[(df_energy['market']==market) & (df_energy['node']==node),['date','hr_beg','price']].rename(columns={'price':'price'+\"_\"+newmarkets[i]+\"_\"+newnodes[j],\n",
    "                                                                                                                    })\n",
    "        energy_output = energy_output.merge(subset, on=['date','hr_beg'], how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_output.drop_duplicates(inplace=True) #why so many dupes?\n",
    "energy_output.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_output.to_csv(\"df_energy_price.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \n",
    "\n",
    "\n",
    "# 5. Generation -- DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/margaretmccall/Documents/2020 Spring/CE 295/0 - Final Project/data_dump_will/'\n",
    "df_gen = pd.read_csv(path+'ERCOT_hourly_by_BA_v5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen['dt'] = pd.to_datetime(df_gen['datetime']) #this seems to be central time\n",
    "df_gen = get_utc(df_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen['date'] = df_gen['UTC'].dt.date\n",
    "df_gen['hr_beg'] = df_gen['UTC'].dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen.drop(columns=['local_time_cems','utc','datetime','UTC','Central','dt'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen.drop_duplicates(inplace=True)\n",
    "df_gen.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen.to_csv('df_generation.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \n",
    "\n",
    "\n",
    "# 6.Weather -- DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading all data and concatenating\n",
    "path = r'/Users/margaretmccall/Documents/2020 Spring/CE 295/0 - Final Project/Data--ERCOT/Weather_Assumptions'\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "df_weather = pd.concat((pd.read_csv(f) for f in all_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather.drop_duplicates(subset=['DeliveryDate','HourEnding'], keep=\"first\", inplace=True)\n",
    "df_weather.sort_values(by=['DeliveryDate','HourEnding'], inplace=True)\n",
    "df_weather.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining date and time to single datetime\n",
    "df_weather['dt'] = pd.to_datetime(df_weather['DeliveryDate'] + \" \" + df_weather['HourEnding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting timezones to UTC\n",
    "df_weather = get_utc(df_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting UTC hour ending to UTC hour beginning, and extracting date and hr_beg from there\n",
    "df_weather['UTC_hr_beg'] = df_weather['UTC'] - datetime.timedelta(hours = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather['date'] = df_weather['UTC_hr_beg'].dt.date\n",
    "df_weather['hr_beg'] = df_weather['UTC_hr_beg'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather.drop(columns=['DeliveryDate','HourEnding','DSTFlag','dt','Central','UTC','UTC_hr_beg'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving. hr_beg is now in UTC\n",
    "df_weather.to_csv('weather_forecast_ercot.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbaseconda588607f9a8224136a0eb124c124b5350"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
